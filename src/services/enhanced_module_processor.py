#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ARQV30 Enhanced v3.0 - Enhanced Module Processor
Processador aprimorado de m√≥dulos com IA
"""

import os
import logging
import asyncio
import json
from typing import Dict, List, Any
from datetime import datetime
from pathlib import Path

# Import do Enhanced AI Manager
from services.enhanced_ai_manager import enhanced_ai_manager
from services.auto_save_manager import salvar_etapa, salvar_erro
# CORRE√á√ÉO 1: Importar os m√≥dulos implementados
try:
    from services.cpl_devastador_protocol import CPLDevastadorProtocol
    from services.avatar_generation_system import AvatarGenerationSystem
    from services.visceral_leads_engineer import VisceralLeadsEngineer
    HAS_ENHANCED_MODULES = True
except ImportError as e:
    logger.warning(f"M√≥dulos aprimorados n√£o encontrados: {e}")
    HAS_ENHANCED_MODULES = False

logger = logging.getLogger(__name__)

class EnhancedModuleProcessor:
    """Processador aprimorado de m√≥dulos"""

    def __init__(self):
        """Inicializa o processador"""
        self.ai_manager = enhanced_ai_manager

        # Lista completa dos m√≥dulos (incluindo o novo m√≥dulo CPL)
        self.modules_config = {
            'anti_objecao': {
                'title': 'Sistema Anti-Obje√ß√£o',
                'description': 'Sistema completo para antecipar e neutralizar obje√ß√µes',
                'use_active_search': False,
                'type': 'standard'
            },
            'avatars': {
                'title': 'Avatares do P√∫blico-Alvo',
                'description': 'Personas detalhadas do p√∫blico-alvo',
                'use_active_search': False,
                'type': 'standard'
            },
            'concorrencia': {
                'title': 'An√°lise Competitiva',
                'description': 'An√°lise completa da concorr√™ncia',
                'use_active_search': True,
                'type': 'standard'
            },
            'drivers_mentais': {
                'title': 'Drivers Mentais',
                'description': 'Gatilhos psicol√≥gicos e drivers de compra',
                'use_active_search': False,
                'type': 'standard'
            },
            'funil_vendas': {
                'title': 'Funil de Vendas',
                'description': 'Estrutura completa do funil de vendas',
                'use_active_search': False,
                'type': 'standard'
            },
            'insights_mercado': {
                'title': 'Insights de Mercado',
                'description': 'Insights profundos sobre o mercado',
                'use_active_search': True,
                'type': 'standard'
            },
            'palavras_chave': {
                'title': 'Estrat√©gia de Palavras-Chave',
                'description': 'Estrat√©gia completa de SEO e palavras-chave',
                'use_active_search': False,
                'type': 'standard'
            },
            'plano_acao': {
                'title': 'Plano de A√ß√£o',
                'description': 'Plano de a√ß√£o detalhado e execut√°vel',
                'use_active_search': False,
                'type': 'standard'
            },
            'posicionamento': {
                'title': 'Estrat√©gia de Posicionamento',
                'description': 'Posicionamento estrat√©gico no mercado',
                'use_active_search': False,
                'type': 'standard'
            },
            'pre_pitch': {
                'title': 'Estrutura de Pr√©-Pitch',
                'description': 'Estrutura de pr√©-venda e engajamento',
                'use_active_search': False,
                'type': 'standard'
            },
            'predicoes_futuro': {
                'title': 'Predi√ß√µes de Mercado',
                'description': 'Predi√ß√µes e tend√™ncias futuras',
                'use_active_search': True,
                'type': 'standard'
            },
            'provas_visuais': {
                'title': 'Sistema de Provas Visuais',
                'description': 'Provas visuais e sociais',
                'use_active_search': False,
                'type': 'standard'
            },
            'metricas_conversao': {
                'title': 'M√©tricas de Convers√£o',
                'description': 'KPIs e m√©tricas de convers√£o',
                'use_active_search': False,
                'type': 'standard'
            },
            'estrategia_preco': {
                'title': 'Estrat√©gia de Precifica√ß√£o',
                'description': 'Estrat√©gia de pre√ßos e monetiza√ß√£o',
                'use_active_search': False,
                'type': 'standard'
            },
            'canais_aquisicao': {
                'title': 'Canais de Aquisi√ß√£o',
                'description': 'Canais de aquisi√ß√£o de clientes',
                'use_active_search': False,
                'type': 'standard'
            },
            'cronograma_lancamento': {
                'title': 'Cronograma de Lan√ßamento',
                'description': 'Cronograma detalhado de lan√ßamento',
                'use_active_search': False,
                'type': 'standard'
            },
            'cpl_completo': {
                'title': 'Protocolo Integrado de CPLs Devastadores',
                'description': 'Protocolo completo para cria√ß√£o de sequ√™ncia de 4 CPLs de alta performance',
                'use_active_search': True,
                'type': 'specialized',
                'requires': ['sintese_master', 'avatar_data', 'contexto_estrategico', 'dados_web']
            },
            # M√≥dulos adicionais para completar os 26 m√≥dulos
            'analise_sentimento': {
                'title': 'An√°lise de Sentimento Detalhada',
                'description': 'An√°lise profunda do sentimento do mercado',
                'use_active_search': True,
                'type': 'standard'
            },
            'mapeamento_tendencias': {
                'title': 'Mapeamento de Tend√™ncias',
                'description': 'Identifica√ß√£o e an√°lise de tend√™ncias emergentes',
                'use_active_search': True,
                'type': 'standard'
            },
            'oportunidades_mercado': {
                'title': 'Oportunidades de Mercado',
                'description': 'Identifica√ß√£o de oportunidades n√£o exploradas',
                'use_active_search': True,
                'type': 'standard'
            },
            'riscos_ameacas': {
                'title': 'Avalia√ß√£o de Riscos e Amea√ßas',
                'description': 'An√°lise de riscos e amea√ßas do mercado',
                'use_active_search': True,
                'type': 'standard'
            },
            'conteudo_viral': {
                'title': 'An√°lise de Conte√∫do Viral',
                'description': 'Fatores de sucesso em conte√∫do viral',
                'use_active_search': False,
                'type': 'standard'
            }
        }

        logger.info("üöÄ Enhanced Module Processor inicializado")

    async def generate_all_modules(self, session_id: str) -> Dict[str, Any]:
        """Gera todos os m√≥dulos (16 padr√£o + 1 especializado CPL)"""
        logger.info(f"üöÄ Iniciando gera√ß√£o de todos os m√≥dulos para sess√£o: {session_id}")

        # Carrega dados base
        base_data = self._load_base_data(session_id)

        results = {
            "session_id": session_id,
            "successful_modules": 0,
            "failed_modules": 0,
            "modules_generated": [],
            "modules_failed": [],
            "total_modules": len(self.modules_config)
        }

        # Cria diret√≥rio de m√≥dulos
        modules_dir = Path(f"analyses_data/{session_id}/modules")
        modules_dir.mkdir(parents=True, exist_ok=True)

        # Gera cada m√≥dulo
        for module_name, config in self.modules_config.items():
            try:
                logger.info(f"üìù Gerando m√≥dulo: {module_name}")

                # Verifica se √© o m√≥dulo especializado CPL
                if module_name == 'cpl_completo':
                    # CORRE√á√ÉO 2: Chamar a fun√ß√£o com o nome correto e argumentos ajustados
                    # Gera o m√≥dulo CPL especializado
                    cpl_content = await create_devastating_cpl_protocol(
                        sintese_master=base_data.get('sintese_master', {}),
                        avatar_data=base_data.get('avatar_data', {}),
                        contexto_estrategico=base_data.get('contexto_estrategico', {}),
                        dados_web=base_data.get('dados_web', {}),
                        session_id=session_id # session_id passado como keyword argument
                    )
                    
                    # Salva conte√∫do do m√≥dulo CPL em formato JSON e Markdown
                    cpl_json_path = modules_dir / f"{module_name}.json"
                    with open(cpl_json_path, 'w', encoding='utf-8') as f:
                        json.dump(cpl_content, f, ensure_ascii=False, indent=2)
                    
                    # Cria vers√£o Markdown do conte√∫do CPL
                    cpl_md_content = self._format_cpl_content_to_markdown(cpl_content)
                    cpl_md_path = modules_dir / f"{module_name}.md"
                    with open(cpl_md_path, 'w', encoding='utf-8') as f:
                        f.write(cpl_md_content)
                else:
                    # Gera conte√∫do do m√≥dulo padr√£o
                    if config.get('use_active_search', False):
                        content = await self.ai_manager.generate_with_active_search(
                            prompt=self._get_module_prompt(module_name, config, base_data),
                            context=base_data.get('context', ''),
                            session_id=session_id
                        )
                    else:
                        content = await self.ai_manager.generate_text(
                            prompt=self._get_module_prompt(module_name, config, base_data)
                        )

                    # Salva m√≥dulo padr√£o
                    module_path = modules_dir / f"{module_name}.md"
                    with open(module_path, 'w', encoding='utf-8') as f:
                        f.write(content)

                results["successful_modules"] += 1
                results["modules_generated"].append(module_name)

                logger.info(f"‚úÖ M√≥dulo {module_name} gerado com sucesso")

            except Exception as e:
                logger.error(f"‚ùå Erro ao gerar m√≥dulo {module_name}: {e}")
                salvar_erro(f"modulo_{module_name}", e, contexto={"session_id": session_id})
                results["failed_modules"] += 1
                results["modules_failed"].append({
                    "module": module_name,
                    "error": str(e)
                })

        # Gera relat√≥rio consolidado
        await self._generate_consolidated_report(session_id, results)

        logger.info(f"‚úÖ Gera√ß√£o conclu√≠da: {results['successful_modules']}/{results['total_modules']} m√≥dulos")

        return results

    def _load_base_data(self, session_id: str) -> Dict[str, Any]:
        """Carrega dados base da sess√£o"""
        try:
            session_dir = Path(f"analyses_data/{session_id}")

            # Carrega s√≠nteses
            synthesis_data = {}
            for synthesis_file in session_dir.glob("sintese_*.json"):
                try:
                    with open(synthesis_file, 'r', encoding='utf-8') as f:
                        synthesis_data[synthesis_file.stem] = json.load(f)
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è Erro ao carregar s√≠ntese {synthesis_file}: {e}")

            # Carrega relat√≥rio de coleta
            coleta_content = ""
            coleta_file = session_dir / "relatorio_coleta.md"
            if coleta_file.exists():
                with open(coleta_file, 'r', encoding='utf-8') as f:
                    coleta_content = f.read()

            # Carrega dados espec√≠ficos para o m√≥dulo CPL
            sintese_master = {}
            avatar_data = {}
            contexto_estrategico = {}
            dados_web = {}
            
            # Tenta carregar a s√≠ntese master
            sintese_master_file = session_dir / "sintese_master_synthesis.json"
            if sintese_master_file.exists():
                try:
                    with open(sintese_master_file, 'r', encoding='utf-8') as f:
                        sintese_master = json.load(f)
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è Erro ao carregar s√≠ntese master: {e}")
            
            # Tenta carregar dados do avatar
            avatar_file = session_dir / "avatar_detalhado.json"
            if avatar_file.exists():
                try:
                    with open(avatar_file, 'r', encoding='utf-8') as f:
                        avatar_data = json.load(f)
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è Erro ao carregar dados do avatar: {e}")
            
            # Tenta carregar contexto estrat√©gico
            contexto_file = session_dir / "contexto_estrategico.json"
            if contexto_file.exists():
                try:
                    with open(contexto_file, 'r', encoding='utf-8') as f:
                        contexto_estrategico = json.load(f)
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è Erro ao carregar contexto estrat√©gico: {e}")
            
            # Tenta carregar dados da web
            web_data_file = session_dir / "dados_pesquisa_web.json"
            if web_data_file.exists():
                try:
                    with open(web_data_file, 'r', encoding='utf-8') as f:
                        dados_web = json.load(f)
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è Erro ao carregar dados da web: {e}")

            return {
                "synthesis_data": synthesis_data,
                "coleta_content": coleta_content,
                "context": f"Dados de s√≠ntese: {len(synthesis_data)} arquivos. Relat√≥rio de coleta: {len(coleta_content)} caracteres.",
                "sintese_master": sintese_master,
                "avatar_data": avatar_data,
                "contexto_estrategico": contexto_estrategico,
                "dados_web": dados_web
            }

        except Exception as e:
            logger.error(f"‚ùå Erro ao carregar dados base: {e}")
            return {
                "synthesis_data": {}, 
                "coleta_content": "", 
                "context": "",
                "sintese_master": {},
                "avatar_data": {},
                "contexto_estrategico": {},
                "dados_web": {}
            }

    def _get_module_prompt(self, module_name: str, config: Dict[str, Any], base_data: Dict[str, Any]) -> str:
        """Gera prompt para um m√≥dulo espec√≠fico"""

        base_prompt = f"""# {config['title']}

Voc√™ √© um especialista em {config['description'].lower()}.

## DADOS DISPON√çVEIS:
{base_data.get('context', 'Dados limitados')}

## TAREFA:
Crie um m√≥dulo ultra-detalhado sobre {config['title']} baseado nos dados coletados.

## ESTRUTURA OBRIGAT√ìRIA:
1. **Resumo Executivo**
2. **An√°lise Detalhada**
3. **Estrat√©gias Espec√≠ficas**
4. **Implementa√ß√£o Pr√°tica**
5. **M√©tricas e KPIs**
6. **Cronograma de Execu√ß√£o**

## REQUISITOS:
- M√≠nimo 2000 palavras
- Dados espec√≠ficos do mercado brasileiro
- Estrat√©gias acion√°veis
- M√©tricas mensur√°veis
- Formato markdown profissional

## CONTEXTO DOS DADOS COLETADOS:
{base_data.get('coleta_content', '')[:1000]}...

Gere um conte√∫do extremamente detalhado e pr√°tico.
"""

        return base_prompt

    def _format_cpl_content_to_markdown(self, cpl_content: Dict[str, Any]) -> str:
        """Formata o conte√∫do do m√≥dulo CPL para Markdown"""
        try:
            markdown_content = f"""# {cpl_content.get('titulo', 'Protocolo de CPLs Devastadores')}

{cpl_content.get('descricao', '')}

"""

            # Adiciona cada fase do protocolo
            fases = cpl_content.get('fases', {})
            for fase_key, fase_data in fases.items():
                markdown_content += f"## {fase_data.get('titulo', fase_key)}\n\n"
                markdown_content += f"**{fase_data.get('descricao', '')}**\n\n"
                
                # Adiciona se√ß√µes espec√≠ficas de cada fase
                if 'estrategia' in fase_data:
                    markdown_content += f"### Estrat√©gia\n{fase_data['estrategia']}\n\n"
                
                if 'versoes_evento' in fase_data:
                    markdown_content += "### Vers√µes do Evento\n"
                    for versao in fase_data['versoes_evento']:
                        markdown_content += f"- **{versao.get('nome_evento', '')}** ({versao.get('tipo', '')}): {versao.get('justificativa_psicologica', '')}\n"
                    markdown_content += "\n"
                
                if 'teasers' in fase_data:
                    markdown_content += "### Teasers\n"
                    for teaser in fase_data['teasers']:
                        markdown_content += f"- {teaser.get('texto', '')} (*{teaser.get('justificativa', '')}*)\n"
                    markdown_content += "\n"
                
                if 'historia_transformacao' in fase_data:
                    ht = fase_data['historia_transformacao']
                    markdown_content += "### Hist√≥ria de Transforma√ß√£o\n"
                    markdown_content += f"- **Antes**: {ht.get('antes', '')}\n"
                    markdown_content += f"- **Durante**: {ht.get('durante', '')}\n"
                    markdown_content += f"- **Depois**: {ht.get('depois', '')}\n\n"
                
                # Adiciona outras se√ß√µes conforme necess√°rio...
                markdown_content += "---\n\n"
            
            # Adiciona considera√ß√µes finais
            consideracoes = cpl_content.get('consideracoes_finais', {})
            if consideracoes:
                markdown_content += "## Considera√ß√µes Finais\n\n"
                markdown_content += f"**Impacto Previsto**: {consideracoes.get('impacto_previsto', '')}\n\n"
                
                if consideracoes.get('diferenciais'):
                    markdown_content += "### Diferenciais\n"
                    for diferencial in consideracoes['diferenciais']:
                        markdown_content += f"- {diferencial}\n"
                    markdown_content += "\n"
                
                if consideracoes.get('proximos_passos'):
                    markdown_content += "### Pr√≥ximos Passos\n"
                    for passo in consideracoes['proximos_passos']:
                        markdown_content += f"- {passo}\n"
                    markdown_content += "\n"

            return markdown_content
            
        except Exception as e:
            logger.error(f"‚ùå Erro ao formatar conte√∫do CPL para Markdown: {e}")
            return "# Protocolo de CPLs Devastadores\n\n*Erro ao gerar conte√∫do formatado*"

    async def _generate_consolidated_report(self, session_id: str, results: Dict[str, Any]) -> None:
        """Gera relat√≥rio consolidado final"""
        try:
            logger.info("üìã Gerando relat√≥rio consolidado final...")

            # Carrega todos os m√≥dulos gerados
            modules_dir = Path(f"analyses_data/{session_id}/modules")
            consolidated_content = f"""# RELAT√ìRIO FINAL CONSOLIDADO - ARQV30 Enhanced v3.0

**Sess√£o:** {session_id}  
**Data:** {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}  
**M√≥dulos Gerados:** {results['successful_modules']}/{results['total_modules']}  
**Taxa de Sucesso:** {(results['successful_modules']/results['total_modules']*100):.1f}%

---

## SUM√ÅRIO EXECUTIVO

Este relat√≥rio consolida {results['successful_modules']} m√≥dulos especializados de an√°lise estrat√©gica gerados pelo sistema ARQV30 Enhanced v3.0.

## M√ìDULOS INCLU√çDOS

"""

            # Adiciona cada m√≥dulo gerado (incluindo o novo CPL)
            for module_name in results['modules_generated']:
                # Trata o m√≥dulo CPL de forma especial
                if module_name == 'cpl_completo':
                    cpl_json_file = modules_dir / f"{module_name}.json"
                    if cpl_json_file.exists():
                        try:
                            with open(cpl_json_file, 'r', encoding='utf-8') as f:
                                cpl_data = json.load(f)
                                title = cpl_data.get('titulo', self.modules_config[module_name]['title'])
                                descricao = cpl_data.get('descricao', '')
                                consolidated_content += f"\n## {title}\n\n{descricao}\n\n"
                                
                                # Adiciona um resumo das fases
                                fases = cpl_data.get('fases', {})
                                if fases:
                                    consolidated_content += "### Fases do Protocolo:\n"
                                    for fase_key, fase_data in fases.items():
                                        consolidated_content += f"- **{fase_data.get('titulo', fase_key)}**: {fase_data.get('descricao', '')[:100]}...\n"
                                    consolidated_content += "\n"
                        except Exception as e:
                            logger.warning(f"‚ö†Ô∏è Erro ao carregar conte√∫do CPL para relat√≥rio: {e}")
                            consolidated_content += f"\n## {self.modules_config[module_name]['title']}\n\n*Conte√∫do n√£o dispon√≠vel*\n\n"
                    else:
                        consolidated_content += f"\n## {self.modules_config[module_name]['title']}\n\n*Conte√∫do n√£o gerado*\n\n"
                else:
                    # Trata m√≥dulos padr√£o
                    module_file = modules_dir / f"{module_name}.md"
                    if module_file.exists():
                        try:
                            with open(module_file, 'r', encoding='utf-8') as f:
                                content = f.read()
                                title = self.modules_config[module_name]['title']
                                # Extrai apenas o t√≠tulo e resumo executivo para o relat√≥rio consolidado
                                lines = content.split('\n')
                                summary_lines = []
                                in_executive_summary = False
                                
                                for line in lines:
                                    if line.startswith('# ') and 'Resumo Executivo' in line:
                                        in_executive_summary = True
                                        summary_lines.append(line)
                                    elif in_executive_summary and line.startswith('#') and 'Resumo Executivo' not in line:
                                        break
                                    elif in_executive_summary:
                                        summary_lines.append(line)
                                
                                if summary_lines:
                                    consolidated_content += f"\n## {title}\n\n" + '\n'.join(summary_lines[1:10]) + "\n\n"
                                else:
                                    # Se n√£o encontrar resumo executivo, usa as primeiras linhas
                                    consolidated_content += f"\n## {title}\n\n" + '\n'.join(lines[:5]) + "\n\n"
                        except Exception as e:
                            logger.warning(f"‚ö†Ô∏è Erro ao carregar conte√∫do do m√≥dulo {module_name} para relat√≥rio: {e}")
                            consolidated_content += f"\n## {self.modules_config[module_name]['title']}\n\n*Conte√∫do n√£o dispon√≠vel*\n\n"
                consolidated_content += "---\n\n"

            # Adiciona informa√ß√µes de m√≥dulos falhados
            if results['modules_failed']:
                consolidated_content += "\n## M√ìDULOS N√ÉO GERADOS\n\n"
                for failed in results['modules_failed']:
                    consolidated_content += f"- **{failed['module']}**: {failed['error']}\n"

            # Salva relat√≥rio consolidado
            consolidated_path = f"analyses_data/{session_id}/relatorio_final_completo.md"
            with open(consolidated_path, 'w', encoding='utf-8') as f:
                f.write(consolidated_content)

            logger.info(f"‚úÖ Relat√≥rio consolidado salvo em: {consolidated_path}")

        except Exception as e:
            logger.error(f"‚ùå Erro ao gerar relat√≥rio consolidado: {e}")
            salvar_erro("relatorio_consolidado", e, contexto={"session_id": session_id})

# Fun√ß√£o para integra√ß√£o com o protocolo CPL devastador
async def create_devastating_cpl_protocol(sintese_master: Dict[str, Any], 
                                        avatar_data: Dict[str, Any], 
                                        contexto_estrategico: Dict[str, Any], 
                                        dados_web: Dict[str, Any], 
                                        session_id: str) -> Dict[str, Any]:
    """
    Cria protocolo de CPLs devastadores usando os m√≥dulos implementados
    """
    try:
        if not HAS_ENHANCED_MODULES:
            logger.warning("‚ö†Ô∏è M√≥dulos aprimorados n√£o dispon√≠veis, usando fallback")
            return {
                'titulo': 'Protocolo de CPLs Devastadores',
                'descricao': 'M√≥dulos aprimorados n√£o dispon√≠veis - Execute a primeira etapa primeiro',
                'status': 'fallback',
                'fases': {},
                'error': 'M√≥dulos n√£o encontrados'
            }
        
        logger.info("üöÄ Iniciando cria√ß√£o de protocolo CPL devastador")
        
        # Inicializa o protocolo CPL
        cpl_protocol = CPLDevastadorProtocol()
        
        # Extrai dados do contexto
        tema = contexto_estrategico.get('tema', 'Produto/Servi√ßo')
        segmento = contexto_estrategico.get('segmento', 'Mercado')
        publico_alvo = contexto_estrategico.get('publico_alvo', 'P√∫blico-alvo')
        
        # Executa protocolo completo
        resultado_cpl = await cpl_protocol.executar_protocolo_completo(
            tema=tema,
            segmento=segmento, 
            publico_alvo=publico_alvo,
            session_id=session_id
        )
        
        logger.info("‚úÖ Protocolo CPL devastador criado com sucesso")
        return resultado_cpl
        
    except Exception as e:
        logger.error(f"‚ùå Erro ao criar protocolo CPL: {e}")
        return {
            'titulo': 'Protocolo de CPLs Devastadores',
            'descricao': f'Erro na cria√ß√£o: {str(e)}',
            'status': 'error',
            'fases': {},
            'error': str(e)
        }

# Inst√¢ncia global
enhanced_module_processor = EnhancedModuleProcessor()
